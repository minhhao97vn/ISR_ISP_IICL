{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16770d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from influence_functions import calc_influence_single_group_upweight, calc_influence_single_group_pert\n",
    "from utils import set_attr\n",
    "from argparse import Namespace\n",
    "import math\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy.stats import rice\n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "seed = 1\n",
    "noise_name = 'gaussian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e3aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f'brain_tumor_dataset/cvind.mat', 'r+') as f:\n",
    "    cv_indices = f['cvind'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b1199",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = []\n",
    "images = []\n",
    "ori_labels = []\n",
    "masks = []\n",
    "\n",
    "for i in range(1, 3065):\n",
    "    with h5py.File(f'brain_tumor_dataset/{i}.mat', 'r+') as f:\n",
    "        pids.append(f['cjdata']['PID'][()])\n",
    "        images.append(f['cjdata']['image'][()])\n",
    "        masks.append(f['cjdata']['tumorMask'][()])\n",
    "        ori_labels.append((f['cjdata']['label'][()][0][0]-1).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids_str = []\n",
    "for idx in range(len(pids)):\n",
    "    pstr = \"\"\n",
    "    for sub in pids[idx]:\n",
    "        pstr+=\"-\"+str(sub[0])\n",
    "    pids_str.append(pstr[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc10fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images\n",
    "normalized_images = []\n",
    "for img in images:\n",
    "    normalized_images.append(img/img.max()*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ffed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images to 256x256\n",
    "\n",
    "max_val = 0\n",
    "\n",
    "for idx, img in enumerate(normalized_images):\n",
    "    if img.shape[0] != 32:\n",
    "        print(f\"Resize image at index {idx} from {img.shape} to 256x256\")\n",
    "        pil_img = Image.fromarray((normalized_images[idx]).astype(np.uint8))\n",
    "        resized_img = np.array(pil_img.resize((256,256)))\n",
    "        normalized_images[idx] = resized_img\n",
    "        \n",
    "        pil_mask = Image.fromarray((masks[idx]))\n",
    "        resized_mask = np.array(pil_mask.resize((256,256)))\n",
    "        masks[idx] = resized_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a414d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))\n",
    "fig.add_subplot(3, 1, 1)\n",
    "plt.imshow(normalized_images[0])\n",
    "\n",
    "fig.add_subplot(3, 1, 2)\n",
    "plt.imshow(masks[0])\n",
    "\n",
    "fig.add_subplot(3, 1, 3)\n",
    "plt.imshow(np.clip(normalized_images[0]+masks[0]*64,0,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28adacb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.stack(normalized_images, axis=0)\n",
    "masks = np.stack(masks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2971ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorDataset(Dataset):\n",
    "    \"\"\"Brain Tumor Dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data, masks, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.masks = masks\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        target = self.targets[idx]\n",
    "        \n",
    "        img = Image.fromarray(img)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target, idx\n",
    "    \n",
    "    def set_subset(self, selected_indices):\n",
    "        self.selected_indices = selected_indices\n",
    "        self.data = self.data[selected_indices]\n",
    "        self.masks = self.masks[selected_indices]\n",
    "        self.targets = self.targets[selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf28442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "def create_large_net_small_linear():\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2d(1, 32, 5, 1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(32, 64, 5, 1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(64, 128, 5, 1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        Flatten(),\n",
    "        nn.Linear(28 * 28 * 128, 3)\n",
    "    )\n",
    "    return net\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.embedding = None\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=32,\n",
    "                kernel_size=5,\n",
    "                stride=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, 5, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 5, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 5, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 5, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # fully connected layer, output 3 classes\n",
    "        self.linear = nn.Linear(4*4*64, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x) \n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        self.cache_embedding(x)\n",
    "        output = self.linear(x)\n",
    "        return output\n",
    "\n",
    "    def cache_embedding(self, embedding):\n",
    "        self.embedding = embedding\n",
    "\n",
    "class FCNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(FCNet, self).__init__()\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.linear(x)\n",
    "        return output\n",
    "        \n",
    "def create_subset_train(selected_indices, current_loader, shuffle_train=True):\n",
    "    train_set = copy.deepcopy(current_loader.dataset)\n",
    "    train_set.set_subset(selected_indices)\n",
    "\n",
    "    return torch.utils.data.DataLoader(train_set, batch_size=32,\n",
    "                                       shuffle=shuffle_train, num_workers=4)\n",
    "\n",
    "def get_indices_to_add_HIN(model, top_model, train_loader_noshfl, val_loader, args):\n",
    "    influences, s_test_vec = calc_influence_single_group_upweight(model, top_model, train_loader_noshfl, val_loader,\n",
    "                                                                  args)\n",
    "\n",
    "    # Get most most harmful examples for adding influence\n",
    "    sorted_indices = [i for i, x in sorted(enumerate(influences), key=lambda x: -x[1], reverse=False)]\n",
    "\n",
    "    influences = np.array([item.cpu().detach().numpy() for item in influences])\n",
    "    selected_indices = sorted_indices[:math.ceil(args.ratio * len(sorted_indices))]\n",
    "\n",
    "    selected_influences = influences[selected_indices]\n",
    "    return influences, selected_influences, selected_indices, s_test_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f2b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test(train_folds, test_folds):\n",
    "    images_train = []\n",
    "    labels_train = []\n",
    "    masks_train = []\n",
    "    \n",
    "    images_test = []\n",
    "    labels_test = []\n",
    "    masks_test = []\n",
    "    for fold_idx in train_folds:\n",
    "        images_train.append(images[(cv_indices[0] == fold_idx)])\n",
    "        labels_train.append(np.array(ori_labels)[(cv_indices[0] == fold_idx)])\n",
    "        masks_train.append(masks[(cv_indices[0] == fold_idx)])\n",
    "        \n",
    "    for fold_idx in test_folds:\n",
    "        images_test.append(images[(cv_indices[0] == fold_idx)])\n",
    "        labels_test.append(np.array(ori_labels)[(cv_indices[0] == fold_idx)])\n",
    "        masks_test.append(masks[(cv_indices[0] == fold_idx)])\n",
    "       \n",
    "    return (np.concatenate(images_train, axis=0), np.concatenate(labels_train, axis=0), np.concatenate(masks_train, axis=0)), (np.concatenate(images_test, axis=0), np.concatenate(labels_test, axis=0), np.concatenate(masks_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd9b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(3))\n",
    "    class_total = list(0. for i in range(3))\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            c = (pred == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    print('Accuracy of the network on the %d test images: %.2f %%' % (len(test_loader.dataset),\n",
    "                                                                    100 * correct / total))\n",
    "\n",
    "    classes = ('meningioma', 'glioma', 'pituitary ')\n",
    "    for i in range(3):\n",
    "        if class_total[i] == 0:\n",
    "            print('Accuracy of %5s : N/A %%' % (classes[i]))\n",
    "        else:\n",
    "            print('Accuracy of %5s : %.2f %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "            \n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647afca1",
   "metadata": {},
   "source": [
    "# Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68559481",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = [1,2,3,5]\n",
    "test_folds = [4]\n",
    "\n",
    "(images_train, labels_train, masks_train), (images_test, labels_test, masks_test) = build_train_test(train_folds, test_folds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcfcaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_lb_test = np.array(labels_test)\n",
    "arr_lb_train = np.array(labels_train)\n",
    "print(\"Number of samples per class in test: \")\n",
    "print('menin:',len(arr_lb_test[arr_lb_test == 0]))\n",
    "print('glio:',len(arr_lb_test[arr_lb_test == 1]))\n",
    "print('pitu:',len(arr_lb_test[arr_lb_test == 2]))\n",
    "print(\"Number of samples per class in train: \")\n",
    "print('menin:', len(arr_lb_train[arr_lb_train == 0]))\n",
    "print('glio:', len(arr_lb_train[arr_lb_train == 1]))\n",
    "print('pitu:', len(arr_lb_train[arr_lb_train == 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a216f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pids_str = []\n",
    "test_pids_str = []\n",
    "for fold_idx in train_folds:\n",
    "        train_pids_str.append(np.stack(pids_str)[(cv_indices[0] == fold_idx)])\n",
    "train_pids_str = np.concatenate(train_pids_str)\n",
    "for fold_idx in test_folds:\n",
    "        test_pids_str.append(np.stack(pids_str)[(cv_indices[0] == fold_idx)])\n",
    "test_pids_str = np.concatenate(test_pids_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc8f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pid_maps(ds_pids_str, ds_labels):\n",
    "    pid_idx_map = {}\n",
    "    pid_label_map = {}\n",
    "    for idx in range(len(ds_pids_str)):\n",
    "        if ds_pids_str[idx] not in pid_idx_map.keys():\n",
    "            pid_idx_map[ds_pids_str[idx]] = [idx]\n",
    "            pid_label_map[ds_pids_str[idx]] = ds_labels[idx]\n",
    "        else:\n",
    "            pid_idx_map[ds_pids_str[idx]].append(idx)\n",
    "            \n",
    "    return pid_idx_map, pid_label_map\n",
    "            \n",
    "train_pid_idx_map, train_pid_label_map = get_pid_maps(train_pids_str, labels_train)\n",
    "test_pid_idx_map, test_pid_label_map = get_pid_maps(test_pids_str, labels_test)\n",
    "all_pid_idx_map, all_pid_label_map = get_pid_maps(pids_str, ori_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04654a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of patients per class in all: \")\n",
    "print('>>> menin:',len(np.where(np.array(list(all_pid_label_map.values())) == 0)[0]))\n",
    "print('>>> glio:', len(np.where(np.array(list(all_pid_label_map.values())) == 1)[0]))\n",
    "print('>>> pitu', len(np.where(np.array(list(all_pid_label_map.values())) == 2)[0]))\n",
    "print('>>> total:', len(all_pid_label_map.keys()))\n",
    "\n",
    "print(\"Number of patients per class in train: \")\n",
    "print('>>> menin:',len(np.where(np.array(list(train_pid_label_map.values())) == 0)[0]))\n",
    "print('>>> glio:', len(np.where(np.array(list(train_pid_label_map.values())) == 1)[0]))\n",
    "print('>>> pitu', len(np.where(np.array(list(train_pid_label_map.values())) == 2)[0]))\n",
    "print('>>> total:', len(train_pid_label_map.keys()))\n",
    "\n",
    "print(\"Number of patients per class in test: \")\n",
    "print('>>> menin:',len(np.where(np.array(list(test_pid_label_map.values())) == 0)[0]))\n",
    "print('>>> glio:', len(np.where(np.array(list(test_pid_label_map.values())) == 1)[0]))\n",
    "print('>>> pitu', len(np.where(np.array(list(test_pid_label_map.values())) == 2)[0]))\n",
    "print('>>> total:', len(test_pid_label_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e230ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of patients from train data to create validation data\n",
    "\n",
    "validate_indices = []\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "patients_per_class = [4,5,3]\n",
    "\n",
    "for i in range(3):\n",
    "    indices = np.array(list(train_pid_label_map.values())) == i\n",
    "    choices = np.array(list(train_pid_label_map.keys()))[indices]\n",
    "    selected_pids = np.random.choice(choices, patients_per_class[i], replace=False)\n",
    "    print(selected_pids)\n",
    "    for pid in selected_pids:\n",
    "        selected_indices = train_pid_idx_map[pid]\n",
    "        validate_indices+=selected_indices\n",
    "        print(f\"Select patient '{pid}', image indices (w.r.t train set): {selected_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b71fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_validate = images_train[validate_indices]\n",
    "labels_validate = labels_train[validate_indices]\n",
    "masks_validate = masks_train[validate_indices]\n",
    "\n",
    "new_train_indices = [idx for idx in range(len(images_train)) if idx not in validate_indices]\n",
    "\n",
    "images_train = images_train[new_train_indices]\n",
    "labels_train = labels_train[new_train_indices]\n",
    "masks_train = masks_train[new_train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to training images\n",
    "ratio_train_noise = 1.0\n",
    "selected_samples = np.random.choice(np.arange(len(images_train)), int(len(images_train)*ratio_train_noise), replace=False)\n",
    "\n",
    "noisy_images_train = copy.deepcopy(images_train)\n",
    "noise_shape = noisy_images_train[0].shape\n",
    "for idx in selected_samples:\n",
    "    if noise_name == 'gaussian':\n",
    "        rand_noise = np.random.normal(0, 32.0, noise_shape)\n",
    "    elif noise_name == 'rician':\n",
    "        rand_noise = rice.rvs(b=1, scale=1.0, size = (256,256), random_state=seed)*16.0\n",
    "\n",
    "    noisy_images_train[idx] = np.clip(images_train[idx].astype(int)+rand_noise, 0, 255.0).astype(np.uint8)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to test images\n",
    "ratio_test_noise = 0.0\n",
    "selected_samples = np.random.choice(np.arange(len(images_test)), int(len(images_test)*ratio_test_noise), replace=False)\n",
    "\n",
    "noisy_images_test = copy.deepcopy(images_test)\n",
    "noise_shape = noisy_images_test[0].shape\n",
    "for idx in selected_samples:\n",
    "    if noise_name == 'gaussian':\n",
    "        rand_noise = np.random.normal(0, 32.0, noise_shape)\n",
    "    elif noise_name == 'rician':\n",
    "        rand_noise = rice.rvs(b=1, scale=1.0, size = (256,256), random_state=seed)*16.0\n",
    "\n",
    "    noisy_images_test[idx] = np.clip(images_test[idx].astype(int)+rand_noise, 0, 255.0).astype(np.uint8)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f588e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images_train[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3da66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(noisy_images_train[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e378b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "#     transforms.CenterCrop(256),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "train_set = BrainTumorDataset(data=noisy_images_train, masks=masks_train, targets=labels_train, transform=train_transform)\n",
    "validate_set = BrainTumorDataset(data=images_validate, masks=masks_validate, targets=labels_validate, transform=test_transform)\n",
    "test_set = BrainTumorDataset(data=noisy_images_test, masks=masks_test, targets=labels_test, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=4)\n",
    "validate_loader = DataLoader(validate_set, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_train = {'ori_images_train': images_train,\n",
    "                'noisy_images_train': noisy_images_train,\n",
    "                'labels_train': labels_train,\n",
    "                'masks_train': masks_train}\n",
    "\n",
    "save_data_validate = {'ori_images_validate': images_validate,\n",
    "                'labels_validate': labels_validate,\n",
    "                'masks_validate': masks_validate}\n",
    "\n",
    "save_data_test = {'ori_images_test': images_test,\n",
    "                'labels_test': labels_test,\n",
    "                'masks_test': masks_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_healthy_noise(loader, feature_influence, selected_hin_indices, args):\n",
    "    \n",
    "    images_train_healthy = copy.deepcopy(loader.dataset.data)\n",
    "    ct = 0\n",
    "    with torch.no_grad():\n",
    "        for idx in range(len(feature_influence)):\n",
    "            outputs = model(feature_influence[idx]['img'].to(args.device))\n",
    "            pred_label = torch.argmax(outputs)\n",
    "            if labels_train[selected_hin_indices[idx]] != pred_label:\n",
    "                ct+=1\n",
    "                print(f'Idx: {idx}, Actu label: {labels_train[selected_hin_indices[idx]]}, Pred label: {pred_label}, Prob: {F.softmax(outputs, dim=1)[0][pred_label]}')\n",
    "            images_train_healthy[selected_hin_indices[idx]] = (np.clip(feature_influence[idx]['img'].numpy()-args.gamma*feature_influence[idx]['infl'][0].cpu().numpy(), 0, 1.0)*255).astype(np.uint8)\n",
    "    \n",
    "    return images_train_healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_influence(model, train_loader, validate_loader):\n",
    "    top_model = FCNet(input_size=model.linear.in_features, output_size=model.linear.out_features)\n",
    "    fc_params = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"linear\" in name:\n",
    "            fc_params[name] = param\n",
    "\n",
    "    for name, param in fc_params.items():\n",
    "        set_attr(top_model, name.split(\".\"), param)\n",
    "    top_model.to(args.device)\n",
    "    top_model.eval()\n",
    "\n",
    "    train_set_no_aug = BrainTumorDataset(data=train_loader.dataset.data, masks=train_loader.dataset.masks, targets=train_loader.dataset.targets, transform=test_transform)\n",
    "    train_loader_noshfl = DataLoader(train_set_no_aug, batch_size=32, shuffle=False, num_workers=4)\n",
    "        \n",
    "\n",
    "    if args.ratio == 1.0:\n",
    "        selected_hin_indices = [i for i in range(len(train_loader.dataset.data))]\n",
    "        s_test_vec = None\n",
    "        all_influences = None\n",
    "    else:\n",
    "        all_influences, selected_hin_influences, selected_hin_indices, s_test_vec = get_indices_to_add_HIN(\n",
    "                            model, top_model,\n",
    "                            train_loader_noshfl,\n",
    "                            validate_loader, args)\n",
    "\n",
    "    sub_train_loader = create_subset_train(selected_hin_indices, train_loader_noshfl, shuffle_train=False)\n",
    "    feature_influence = calc_influence_single_group_pert(model, top_model, sub_train_loader, validate_loader, args, s_test_vec)\n",
    "    \n",
    "    return all_influences, feature_influence, selected_hin_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df563043",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "device = 'cuda:1'\n",
    "\n",
    "args_dict = args_dict = {'gamma': 0.1, 'device': device, 'ratio': 1.0, 'damp': 0.05, 'scale': 50, 'recur_depth': len(train_set), 'r_average': 1, 'hvp_batch_size': 10}\n",
    "args = Namespace(**args_dict)\n",
    "\n",
    "model = ConvNet()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "noise_update_epoch = 15\n",
    "\n",
    "best_acc = 0\n",
    "best_acc_epoch = 0\n",
    "\n",
    "test_accs = []\n",
    "train_accs = []\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    if epoch == noise_update_epoch:\n",
    "        model.eval()\n",
    "        \n",
    "        all_influences, feature_influence, selected_hin_indices = get_influence(model, train_loader, validate_loader)\n",
    "        images_train_healthy = add_healthy_noise(train_loader, feature_influence, selected_hin_indices, args)\n",
    "        train_loader.dataset.data = images_train_healthy\n",
    "\n",
    "        \n",
    "        model.train()\n",
    "                \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_loss = 0\n",
    "    count_batch = 0\n",
    "        \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\", unit=\"batch\")\n",
    "    for i, (inputs, targets, _) in enumerate(progress_bar, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        count_batch += 1\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        progress_bar.set_postfix({\"loss\": train_loss/count_batch, \"acc\": correct/total})\n",
    "        \n",
    "    train_losses.append(train_loss/count_batch)\n",
    "    train_accs.append(correct/total)\n",
    "        \n",
    "    \n",
    "        \n",
    "    model.eval()\n",
    "    test_acc = test(test_loader, model, device)\n",
    "    model.train()\n",
    "    \n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    if test_acc >= best_acc:\n",
    "        best_acc = test_acc\n",
    "        best_acc_epoch = epoch\n",
    "        \n",
    "        save_data = {\n",
    "            'best_at_epoch': best_acc_epoch+1,\n",
    "            'best_acc': best_acc,\n",
    "            'model_state': model.state_dict(),\n",
    "            'setup': args_dict\n",
    "        }\n",
    "        \n",
    "        torch.save(save_data, f\"results/isp_trained/dataset_{test_folds[0]}_best_healthy_CNN_model_Gausian_std_32_seed_{seed}.pth\")\n",
    "        \n",
    "    if epoch == num_epochs-1:\n",
    "        save_data = {\n",
    "            'num_epochs': num_epochs,\n",
    "            'test_acc': test_acc,\n",
    "            'model_state': model.state_dict(),\n",
    "            'setup': args_dict\n",
    "        }\n",
    "        \n",
    "        torch.save(save_data, f\"results/isp_trained/dataset_{test_folds[0]}_last_healthy_CNN_model_Gausian_std_32_seed_{seed}.pth\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d0e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea78c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
